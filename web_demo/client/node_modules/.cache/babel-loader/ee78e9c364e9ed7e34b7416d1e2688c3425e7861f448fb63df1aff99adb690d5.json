{"ast":null,"code":"import \"core-js/modules/es.array.push.js\";\n// Process *this* and _that_\n//\n\n// Insert each marker as a separate text token, and add it to delimiter list\n//\nfunction emphasis_tokenize(state, silent) {\n  const start = state.pos;\n  const marker = state.src.charCodeAt(start);\n  if (silent) {\n    return false;\n  }\n  if (marker !== 0x5F /* _ */ && marker !== 0x2A /* * */) {\n    return false;\n  }\n  const scanned = state.scanDelims(state.pos, marker === 0x2A);\n  for (let i = 0; i < scanned.length; i++) {\n    const token = state.push('text', '', 0);\n    token.content = String.fromCharCode(marker);\n    state.delimiters.push({\n      // Char code of the starting marker (number).\n      //\n      marker,\n      // Total length of these series of delimiters.\n      //\n      length: scanned.length,\n      // A position of the token this delimiter corresponds to.\n      //\n      token: state.tokens.length - 1,\n      // If this delimiter is matched as a valid opener, `end` will be\n      // equal to its position, otherwise it's `-1`.\n      //\n      end: -1,\n      // Boolean flags that determine if this delimiter could open or close\n      // an emphasis.\n      //\n      open: scanned.can_open,\n      close: scanned.can_close\n    });\n  }\n  state.pos += scanned.length;\n  return true;\n}\nfunction postProcess(state, delimiters) {\n  const max = delimiters.length;\n  for (let i = max - 1; i >= 0; i--) {\n    const startDelim = delimiters[i];\n    if (startDelim.marker !== 0x5F /* _ */ && startDelim.marker !== 0x2A /* * */) {\n      continue;\n    }\n\n    // Process only opening markers\n    if (startDelim.end === -1) {\n      continue;\n    }\n    const endDelim = delimiters[startDelim.end];\n\n    // If the previous delimiter has the same marker and is adjacent to this one,\n    // merge those into one strong delimiter.\n    //\n    // `<em><em>whatever</em></em>` -> `<strong>whatever</strong>`\n    //\n    const isStrong = i > 0 && delimiters[i - 1].end === startDelim.end + 1 &&\n    // check that first two markers match and adjacent\n    delimiters[i - 1].marker === startDelim.marker && delimiters[i - 1].token === startDelim.token - 1 &&\n    // check that last two markers are adjacent (we can safely assume they match)\n    delimiters[startDelim.end + 1].token === endDelim.token + 1;\n    const ch = String.fromCharCode(startDelim.marker);\n    const token_o = state.tokens[startDelim.token];\n    token_o.type = isStrong ? 'strong_open' : 'em_open';\n    token_o.tag = isStrong ? 'strong' : 'em';\n    token_o.nesting = 1;\n    token_o.markup = isStrong ? ch + ch : ch;\n    token_o.content = '';\n    const token_c = state.tokens[endDelim.token];\n    token_c.type = isStrong ? 'strong_close' : 'em_close';\n    token_c.tag = isStrong ? 'strong' : 'em';\n    token_c.nesting = -1;\n    token_c.markup = isStrong ? ch + ch : ch;\n    token_c.content = '';\n    if (isStrong) {\n      state.tokens[delimiters[i - 1].token].content = '';\n      state.tokens[delimiters[startDelim.end + 1].token].content = '';\n      i--;\n    }\n  }\n}\n\n// Walk through delimiter list and replace text tokens with tags\n//\nfunction emphasis_post_process(state) {\n  const tokens_meta = state.tokens_meta;\n  const max = state.tokens_meta.length;\n  postProcess(state, state.delimiters);\n  for (let curr = 0; curr < max; curr++) {\n    if (tokens_meta[curr] && tokens_meta[curr].delimiters) {\n      postProcess(state, tokens_meta[curr].delimiters);\n    }\n  }\n}\nexport default {\n  tokenize: emphasis_tokenize,\n  postProcess: emphasis_post_process\n};","map":{"version":3,"names":["emphasis_tokenize","state","silent","start","pos","marker","src","charCodeAt","scanned","scanDelims","i","length","token","push","content","String","fromCharCode","delimiters","tokens","end","open","can_open","close","can_close","postProcess","max","startDelim","endDelim","isStrong","ch","token_o","type","tag","nesting","markup","token_c","emphasis_post_process","tokens_meta","curr","tokenize"],"sources":["E:/GLM-UML/web_demo/client/node_modules/markdown-it/lib/rules_inline/emphasis.mjs"],"sourcesContent":["// Process *this* and _that_\n//\n\n// Insert each marker as a separate text token, and add it to delimiter list\n//\nfunction emphasis_tokenize (state, silent) {\n  const start = state.pos\n  const marker = state.src.charCodeAt(start)\n\n  if (silent) { return false }\n\n  if (marker !== 0x5F /* _ */ && marker !== 0x2A /* * */) { return false }\n\n  const scanned = state.scanDelims(state.pos, marker === 0x2A)\n\n  for (let i = 0; i < scanned.length; i++) {\n    const token = state.push('text', '', 0)\n    token.content = String.fromCharCode(marker)\n\n    state.delimiters.push({\n      // Char code of the starting marker (number).\n      //\n      marker,\n\n      // Total length of these series of delimiters.\n      //\n      length: scanned.length,\n\n      // A position of the token this delimiter corresponds to.\n      //\n      token: state.tokens.length - 1,\n\n      // If this delimiter is matched as a valid opener, `end` will be\n      // equal to its position, otherwise it's `-1`.\n      //\n      end: -1,\n\n      // Boolean flags that determine if this delimiter could open or close\n      // an emphasis.\n      //\n      open: scanned.can_open,\n      close: scanned.can_close\n    })\n  }\n\n  state.pos += scanned.length\n\n  return true\n}\n\nfunction postProcess (state, delimiters) {\n  const max = delimiters.length\n\n  for (let i = max - 1; i >= 0; i--) {\n    const startDelim = delimiters[i]\n\n    if (startDelim.marker !== 0x5F/* _ */ && startDelim.marker !== 0x2A/* * */) {\n      continue\n    }\n\n    // Process only opening markers\n    if (startDelim.end === -1) {\n      continue\n    }\n\n    const endDelim = delimiters[startDelim.end]\n\n    // If the previous delimiter has the same marker and is adjacent to this one,\n    // merge those into one strong delimiter.\n    //\n    // `<em><em>whatever</em></em>` -> `<strong>whatever</strong>`\n    //\n    const isStrong = i > 0 &&\n               delimiters[i - 1].end === startDelim.end + 1 &&\n               // check that first two markers match and adjacent\n               delimiters[i - 1].marker === startDelim.marker &&\n               delimiters[i - 1].token === startDelim.token - 1 &&\n               // check that last two markers are adjacent (we can safely assume they match)\n               delimiters[startDelim.end + 1].token === endDelim.token + 1\n\n    const ch = String.fromCharCode(startDelim.marker)\n\n    const token_o   = state.tokens[startDelim.token]\n    token_o.type    = isStrong ? 'strong_open' : 'em_open'\n    token_o.tag     = isStrong ? 'strong' : 'em'\n    token_o.nesting = 1\n    token_o.markup  = isStrong ? ch + ch : ch\n    token_o.content = ''\n\n    const token_c   = state.tokens[endDelim.token]\n    token_c.type    = isStrong ? 'strong_close' : 'em_close'\n    token_c.tag     = isStrong ? 'strong' : 'em'\n    token_c.nesting = -1\n    token_c.markup  = isStrong ? ch + ch : ch\n    token_c.content = ''\n\n    if (isStrong) {\n      state.tokens[delimiters[i - 1].token].content = ''\n      state.tokens[delimiters[startDelim.end + 1].token].content = ''\n      i--\n    }\n  }\n}\n\n// Walk through delimiter list and replace text tokens with tags\n//\nfunction emphasis_post_process (state) {\n  const tokens_meta = state.tokens_meta\n  const max = state.tokens_meta.length\n\n  postProcess(state, state.delimiters)\n\n  for (let curr = 0; curr < max; curr++) {\n    if (tokens_meta[curr] && tokens_meta[curr].delimiters) {\n      postProcess(state, tokens_meta[curr].delimiters)\n    }\n  }\n}\n\nexport default {\n  tokenize: emphasis_tokenize,\n  postProcess: emphasis_post_process\n}\n"],"mappings":";AAAA;AACA;;AAEA;AACA;AACA,SAASA,iBAAiBA,CAAEC,KAAK,EAAEC,MAAM,EAAE;EACzC,MAAMC,KAAK,GAAGF,KAAK,CAACG,GAAG;EACvB,MAAMC,MAAM,GAAGJ,KAAK,CAACK,GAAG,CAACC,UAAU,CAACJ,KAAK,CAAC;EAE1C,IAAID,MAAM,EAAE;IAAE,OAAO,KAAK;EAAC;EAE3B,IAAIG,MAAM,KAAK,IAAI,CAAC,WAAWA,MAAM,KAAK,IAAI,CAAC,SAAS;IAAE,OAAO,KAAK;EAAC;EAEvE,MAAMG,OAAO,GAAGP,KAAK,CAACQ,UAAU,CAACR,KAAK,CAACG,GAAG,EAAEC,MAAM,KAAK,IAAI,CAAC;EAE5D,KAAK,IAAIK,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,OAAO,CAACG,MAAM,EAAED,CAAC,EAAE,EAAE;IACvC,MAAME,KAAK,GAAGX,KAAK,CAACY,IAAI,CAAC,MAAM,EAAE,EAAE,EAAE,CAAC,CAAC;IACvCD,KAAK,CAACE,OAAO,GAAGC,MAAM,CAACC,YAAY,CAACX,MAAM,CAAC;IAE3CJ,KAAK,CAACgB,UAAU,CAACJ,IAAI,CAAC;MACpB;MACA;MACAR,MAAM;MAEN;MACA;MACAM,MAAM,EAAEH,OAAO,CAACG,MAAM;MAEtB;MACA;MACAC,KAAK,EAAEX,KAAK,CAACiB,MAAM,CAACP,MAAM,GAAG,CAAC;MAE9B;MACA;MACA;MACAQ,GAAG,EAAE,CAAC,CAAC;MAEP;MACA;MACA;MACAC,IAAI,EAAEZ,OAAO,CAACa,QAAQ;MACtBC,KAAK,EAAEd,OAAO,CAACe;IACjB,CAAC,CAAC;EACJ;EAEAtB,KAAK,CAACG,GAAG,IAAII,OAAO,CAACG,MAAM;EAE3B,OAAO,IAAI;AACb;AAEA,SAASa,WAAWA,CAAEvB,KAAK,EAAEgB,UAAU,EAAE;EACvC,MAAMQ,GAAG,GAAGR,UAAU,CAACN,MAAM;EAE7B,KAAK,IAAID,CAAC,GAAGe,GAAG,GAAG,CAAC,EAAEf,CAAC,IAAI,CAAC,EAAEA,CAAC,EAAE,EAAE;IACjC,MAAMgB,UAAU,GAAGT,UAAU,CAACP,CAAC,CAAC;IAEhC,IAAIgB,UAAU,CAACrB,MAAM,KAAK,IAAI,YAAWqB,UAAU,CAACrB,MAAM,KAAK,IAAI,UAAS;MAC1E;IACF;;IAEA;IACA,IAAIqB,UAAU,CAACP,GAAG,KAAK,CAAC,CAAC,EAAE;MACzB;IACF;IAEA,MAAMQ,QAAQ,GAAGV,UAAU,CAACS,UAAU,CAACP,GAAG,CAAC;;IAE3C;IACA;IACA;IACA;IACA;IACA,MAAMS,QAAQ,GAAGlB,CAAC,GAAG,CAAC,IACXO,UAAU,CAACP,CAAC,GAAG,CAAC,CAAC,CAACS,GAAG,KAAKO,UAAU,CAACP,GAAG,GAAG,CAAC;IAC5C;IACAF,UAAU,CAACP,CAAC,GAAG,CAAC,CAAC,CAACL,MAAM,KAAKqB,UAAU,CAACrB,MAAM,IAC9CY,UAAU,CAACP,CAAC,GAAG,CAAC,CAAC,CAACE,KAAK,KAAKc,UAAU,CAACd,KAAK,GAAG,CAAC;IAChD;IACAK,UAAU,CAACS,UAAU,CAACP,GAAG,GAAG,CAAC,CAAC,CAACP,KAAK,KAAKe,QAAQ,CAACf,KAAK,GAAG,CAAC;IAEtE,MAAMiB,EAAE,GAAGd,MAAM,CAACC,YAAY,CAACU,UAAU,CAACrB,MAAM,CAAC;IAEjD,MAAMyB,OAAO,GAAK7B,KAAK,CAACiB,MAAM,CAACQ,UAAU,CAACd,KAAK,CAAC;IAChDkB,OAAO,CAACC,IAAI,GAAMH,QAAQ,GAAG,aAAa,GAAG,SAAS;IACtDE,OAAO,CAACE,GAAG,GAAOJ,QAAQ,GAAG,QAAQ,GAAG,IAAI;IAC5CE,OAAO,CAACG,OAAO,GAAG,CAAC;IACnBH,OAAO,CAACI,MAAM,GAAIN,QAAQ,GAAGC,EAAE,GAAGA,EAAE,GAAGA,EAAE;IACzCC,OAAO,CAAChB,OAAO,GAAG,EAAE;IAEpB,MAAMqB,OAAO,GAAKlC,KAAK,CAACiB,MAAM,CAACS,QAAQ,CAACf,KAAK,CAAC;IAC9CuB,OAAO,CAACJ,IAAI,GAAMH,QAAQ,GAAG,cAAc,GAAG,UAAU;IACxDO,OAAO,CAACH,GAAG,GAAOJ,QAAQ,GAAG,QAAQ,GAAG,IAAI;IAC5CO,OAAO,CAACF,OAAO,GAAG,CAAC,CAAC;IACpBE,OAAO,CAACD,MAAM,GAAIN,QAAQ,GAAGC,EAAE,GAAGA,EAAE,GAAGA,EAAE;IACzCM,OAAO,CAACrB,OAAO,GAAG,EAAE;IAEpB,IAAIc,QAAQ,EAAE;MACZ3B,KAAK,CAACiB,MAAM,CAACD,UAAU,CAACP,CAAC,GAAG,CAAC,CAAC,CAACE,KAAK,CAAC,CAACE,OAAO,GAAG,EAAE;MAClDb,KAAK,CAACiB,MAAM,CAACD,UAAU,CAACS,UAAU,CAACP,GAAG,GAAG,CAAC,CAAC,CAACP,KAAK,CAAC,CAACE,OAAO,GAAG,EAAE;MAC/DJ,CAAC,EAAE;IACL;EACF;AACF;;AAEA;AACA;AACA,SAAS0B,qBAAqBA,CAAEnC,KAAK,EAAE;EACrC,MAAMoC,WAAW,GAAGpC,KAAK,CAACoC,WAAW;EACrC,MAAMZ,GAAG,GAAGxB,KAAK,CAACoC,WAAW,CAAC1B,MAAM;EAEpCa,WAAW,CAACvB,KAAK,EAAEA,KAAK,CAACgB,UAAU,CAAC;EAEpC,KAAK,IAAIqB,IAAI,GAAG,CAAC,EAAEA,IAAI,GAAGb,GAAG,EAAEa,IAAI,EAAE,EAAE;IACrC,IAAID,WAAW,CAACC,IAAI,CAAC,IAAID,WAAW,CAACC,IAAI,CAAC,CAACrB,UAAU,EAAE;MACrDO,WAAW,CAACvB,KAAK,EAAEoC,WAAW,CAACC,IAAI,CAAC,CAACrB,UAAU,CAAC;IAClD;EACF;AACF;AAEA,eAAe;EACbsB,QAAQ,EAAEvC,iBAAiB;EAC3BwB,WAAW,EAAEY;AACf,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}